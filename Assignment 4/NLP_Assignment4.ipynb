{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** *What is Topic Modeling? (10)*\n",
    "\n",
    "Topic Modeling is an unsupervised method in which we can identify topic by words and document by topic, without pre-tagged/labeled texts. There are multiple types of topic modeling algorithms, such as SVD and LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2** *What is Document Clustering? Explain it using the K-means algorithm and provide a program to illustrate the concept.(10)*\n",
    "\n",
    "Document Clustering is assigning categories to documents based on content similarity without needing labels. We can use k-means to do document clustering by transforming the documents into TF-IDF vector, then the k-means algorithm selects k number of random centroids, assigns each document to cluster via cosine similarity, then the algorithm updates centroids based on averaging the vectors of the documents, and repeats the process from cosine similarity until a convergence is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: Cluster 0\n",
      "Document 2: Cluster 0\n",
      "Document 3: Cluster 0\n",
      "Document 4: Cluster 0\n",
      "Document 5: Cluster 1\n",
      "Document 6: Cluster 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "documents = [\n",
    "    \"Machine learning is amazing\",\n",
    "    \"Natural language processing is a part of AI\",\n",
    "    \"Deep learning and neural networks\",\n",
    "    \"AI is transforming the world\",\n",
    "    \"Clustering techniques like K-means are useful\",\n",
    "    \"K-means is used for document clustering\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Document {i+1}: Cluster {kmeans.labels_[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3** *What is Singular Value Decomposition (SVD)? Describe its diagonal matrix and the matrices obtained through its decomposition. How is SVD applied in topic modeling? Include a program to demonstrate its application. (10)*\n",
    "\n",
    "Singular Value Decomposition is a method of decomposing a vector A into three vectors, U which represents document-topic relationships, Σ which is the singular value matrix which represents importance of each topic, and V<sup>T</sup> which represents topic-word relationships. SVD is applied in topic modeling by allowing us to see document-topic importance, as well as topic-word importance, by manipulating just a dataset of untagged/unlabeled documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix A:\n",
      "[[0.         0.61171251 0.         0.         0.         0.\n",
      "  0.50161301 0.         0.61171251 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.42790272 0.         0.         0.         0.         0.52182349\n",
      "  0.         0.         0.         0.         0.52182349 0.\n",
      "  0.         0.52182349 0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.52182349 0.         0.\n",
      "  0.42790272 0.         0.         0.         0.         0.52182349\n",
      "  0.52182349 0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.50161301 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.61171251 0.         0.\n",
      "  0.61171251]\n",
      " [0.         0.         0.39339985 0.         0.         0.\n",
      "  0.         0.47974754 0.         0.39339985 0.         0.\n",
      "  0.         0.         0.47974754 0.         0.         0.47974754\n",
      "  0.        ]\n",
      " [0.         0.         0.44836665 0.         0.54677906 0.\n",
      "  0.         0.         0.         0.44836665 0.         0.\n",
      "  0.         0.         0.         0.         0.54677906 0.\n",
      "  0.        ]]\n",
      "\n",
      "U Matrix:\n",
      "[[ 0.00000000e+00  0.00000000e+00 -7.07106781e-01  7.07106781e-01\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 3.66996365e-16  7.07106781e-01  0.00000000e+00  0.00000000e+00\n",
      "   7.07106781e-01 -5.62793785e-17]\n",
      " [ 0.00000000e+00  0.00000000e+00 -7.07106781e-01 -7.07106781e-01\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 6.02835016e-17  7.07106781e-01  1.57813853e-17  2.44076157e-17\n",
      "  -7.07106781e-01 -2.00945005e-17]\n",
      " [-7.07106781e-01  1.75452994e-16  0.00000000e+00  0.00000000e+00\n",
      "   1.35263993e-16 -7.07106781e-01]\n",
      " [-7.07106781e-01  2.51826873e-16  0.00000000e+00  0.00000000e+00\n",
      "   1.71448871e-16  7.07106781e-01]]\n",
      "\n",
      "Σ Matrix (Diagonal):\n",
      "[[1.16308845 0.         0.         0.         0.         0.        ]\n",
      " [0.         1.10210779 0.         0.         0.         0.        ]\n",
      " [0.         0.         1.10210779 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.88620451 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.88620451 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.80450311]]\n",
      "\n",
      "V^T Matrix:\n",
      "[[ 1.04869973e-16 -1.25933288e-17 -5.11757125e-01 -7.01948650e-17\n",
      "  -3.32417696e-01  1.81317201e-16  2.25957327e-17 -2.91665471e-01\n",
      "  -5.93549524e-18 -5.11757125e-01  1.79343538e-16  4.56539102e-17\n",
      "   4.56539102e-17  1.79343538e-16 -2.91665471e-01 -3.07216067e-17\n",
      "  -3.32417696e-01 -2.91665471e-01 -3.07216067e-17]\n",
      " [ 5.96372593e-01 -4.32602781e-17  1.35287561e-16  1.16156845e-18\n",
      "   1.12831228e-16  3.34799310e-01 -5.95984871e-33  4.94994307e-17\n",
      "   1.32326801e-33  1.33113462e-16  3.34799310e-01  8.29729225e-18\n",
      "   8.29729225e-18  3.34799310e-01  4.94994307e-17  3.92471652e-01\n",
      "   1.12831228e-16  4.94994307e-17  3.92471652e-01]\n",
      " [ 3.47855753e-17 -3.92471652e-01  0.00000000e+00 -3.34799310e-01\n",
      "   0.00000000e+00 -8.69639382e-18 -5.96372593e-01  0.00000000e+00\n",
      "  -3.92471652e-01  0.00000000e+00 -8.69639382e-18 -3.34799310e-01\n",
      "  -3.34799310e-01 -8.69639382e-18  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 4.32602781e-17  4.88088315e-01  0.00000000e+00 -4.16365438e-01\n",
      "   0.00000000e+00 -1.08150695e-17  5.88137852e-02  0.00000000e+00\n",
      "   4.88088315e-01  0.00000000e+00 -1.08150695e-17 -4.16365438e-01\n",
      "  -4.16365438e-01 -1.08150695e-17  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-5.88137852e-02 -3.47855753e-17  1.04332724e-16 -1.44455780e-18\n",
      "   9.07275533e-17  4.16365438e-01 -4.79231237e-33  3.98024758e-17\n",
      "   1.06403937e-33  1.07036491e-16  4.16365438e-01 -1.03187361e-17\n",
      "  -1.03187361e-17  4.16365438e-01  3.98024758e-17 -4.88088315e-01\n",
      "   9.07275533e-17  3.98024758e-17 -4.88088315e-01]\n",
      " [-2.60352838e-17  6.09959941e-18  4.83123059e-02  5.26915620e-17\n",
      "   4.80583828e-01 -4.28970148e-17 -3.53801503e-18 -4.21667409e-01\n",
      "  -3.19837647e-18  4.83123059e-02 -4.00436454e-17  3.15786066e-17\n",
      "   3.15786066e-17 -4.00436454e-17 -4.21667409e-01 -4.37582576e-18\n",
      "   4.80583828e-01 -4.21667409e-01 -4.37582576e-18]]\n",
      "\n",
      "A (approximation):\n",
      "[[-8.93873297e-33  6.11712510e-01  0.00000000e+00  5.00713500e-17\n",
      "   0.00000000e+00  2.23468324e-33  5.01613009e-01  0.00000000e+00\n",
      "   6.11712510e-01  0.00000000e+00  2.23468324e-33  5.00713500e-17\n",
      "   5.00713500e-17  2.23468324e-33  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 4.27902725e-01 -5.55111512e-17 -4.98207214e-17 -5.79107159e-33\n",
      "  -1.88677109e-17  5.21823488e-01  2.15754409e-33 -4.18882065e-17\n",
      "  -6.90744785e-34 -4.98207214e-17  5.21823488e-01  4.28190624e-33\n",
      "   4.28190624e-33  5.21823488e-01 -4.18882065e-17 -6.74436095e-17\n",
      "  -1.88677109e-17 -4.18882065e-17 -6.74436095e-17]\n",
      " [-5.42173465e-17 -1.67660647e-16  0.00000000e+00  5.21823488e-01\n",
      "   0.00000000e+00  1.35543366e-17  4.27902725e-01  0.00000000e+00\n",
      "  -1.67660647e-16  0.00000000e+00  1.35543366e-17  5.21823488e-01\n",
      "   5.21823488e-01  1.35543366e-17  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 5.01613009e-01 -8.18375882e-18  3.38858416e-18 -1.30186967e-17\n",
      "  -2.08048524e-32 -1.65120276e-16 -9.10043152e-18 -8.37122930e-33\n",
      "   3.73124201e-18 -2.32458186e-32 -1.65120276e-16 -1.89684500e-18\n",
      "  -1.89684500e-18 -1.65120276e-16 -8.37122930e-33  6.11712510e-01\n",
      "  -1.39516828e-32 -8.37122930e-33  6.11712510e-01]\n",
      " [ 3.68320486e-17  6.88722614e-18  3.93399849e-01  2.77555756e-17\n",
      "  -1.96544394e-16 -1.00676022e-17 -1.65706880e-17  4.79747544e-01\n",
      "   6.70097504e-18  3.93399849e-01 -1.00676022e-17 -5.55111512e-17\n",
      "  -5.55111512e-17 -1.00676022e-17  4.79747544e-01  4.51391698e-17\n",
      "  -1.18039771e-16  4.79747544e-01  4.51391698e-17]\n",
      " [ 5.55227130e-17  1.38269795e-17  4.48366654e-01  8.77048316e-17\n",
      "   5.46779063e-01 -1.73407331e-17 -2.05960264e-17 -1.64937458e-17\n",
      "   3.06205673e-18  4.48366654e-01 -1.40943429e-17 -1.95829324e-17\n",
      "  -1.95829324e-17 -1.40943429e-17 -1.64937458e-17  5.75442155e-17\n",
      "   5.46779063e-01 -1.64937458e-17  5.75442155e-17]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "documents = [\n",
    "    \"Machine learning is amazing\",\n",
    "    \"Natural language processing is a part of AI\",\n",
    "    \"Deep learning and neural networks\",\n",
    "    \"AI is transforming the world\",\n",
    "    \"Clustering techniques like K-means are useful\",\n",
    "    \"K-means is used for document clustering\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "A = vectorizer.fit_transform(documents).toarray()\n",
    "\n",
    "U, Sigma, Vt = np.linalg.svd(A, full_matrices=False)\n",
    "\n",
    "Sigma_matrix = np.diag(Sigma)\n",
    "A_reconstructed = np.dot(U, np.dot(Sigma_matrix, Vt))\n",
    "\n",
    "print(\"Original Matrix A:\")\n",
    "print(A)\n",
    "print(\"\\nU Matrix:\")\n",
    "print(U)\n",
    "print(\"\\nΣ Matrix (Diagonal):\")\n",
    "print(Sigma_matrix)\n",
    "print(\"\\nV^T Matrix:\")\n",
    "print(Vt)\n",
    "print(\"\\nA (approximation):\")\n",
    "print(A_reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** *Can you explain Latent Dirichlet Allocation (LDA) in the context of topic modeling? (10)*\n",
    "\n",
    "LDA is a supervised model that is a conditional probabilistic form of topic modeling. LDA generates topics and classifies words and documents across these topics according to the probability from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5** *What is Non-Negative Matrix Factorization (NMF)? How does it differ from SVD? Can NMF be used for topic modeling? (10)*\n",
    "\n",
    "Non-Negative Matrix Factorization is a Decomposition technique that takes an input matrix(words by document) and decomposes it into two non negative matrices (word by topic and document by topic). It differs from SVD as SVD can contain negative numbers while NMF cannot, as well as SVD utilizes singular values while NMF only uses non-negative constraints. NMF can be used for topic modeling because it decomposes a word by document matrix into a word by topic matrix and a document by topic matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
