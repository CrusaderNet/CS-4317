{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "978c13f1",
   "metadata": {},
   "source": [
    "# 10 Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b288ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Input, Flatten, LSTM, Dropout, Bidirectional, LeakyReLU, Reshape, Lambda\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# performance matrices\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import imblearn\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, auc\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5fd3cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/t326h379/OGP\")\n",
    "\n",
    "\n",
    "df_negative = pd.read_csv('Feature_Extraction_O_linked_Training_Negative_114307_Sites_less.txt',header=None)\n",
    "\n",
    "df_positive = pd.read_csv('Feature_Extraction_O_linked_Training_Positive_4885_Sites_less.txt',header=None)\n",
    "\n",
    "Header_name = [\"Position\",\"PID\",\"Position_redundant\",\"81 Window sequence\",\"S or T\"]\n",
    "\n",
    "col_of_feature = [i for i in range(1,1025)]\n",
    "\n",
    "Header_name = Header_name + col_of_feature\n",
    "\n",
    "df_positive.columns = Header_name\n",
    "df_negative.columns = Header_name\n",
    "\n",
    "\n",
    "frames = [df_positive, df_negative]\n",
    "\n",
    "O_linked_training = pd.concat(frames,ignore_index = True)\n",
    "\n",
    "df_Train_array = O_linked_training.drop([\"Position\",\"PID\",\"Position_redundant\",\"81 Window sequence\",\"S or T\"],axis=1)\n",
    "df_Train_array = np.array(df_Train_array)\n",
    "\n",
    "X_train_full = df_Train_array\n",
    "\n",
    "y_train_full = np.array([1]*4885+[0]*114144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff7457c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = random.sample(range(1, 1000000), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00c649b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed :  848295\n",
      "(9770, 1024)\n",
      "(9770,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.6336088044386692\n",
      "Confusion Matrix : \n",
      " [[401  87]\n",
      " [ 92 397]]\n",
      "Accuracy on test set:    0.8167860798362334\n",
      "Sensitivity:    0.8118609406952966 \t Specificity:    0.8217213114754098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       488\n",
      "           1       0.82      0.81      0.82       489\n",
      "\n",
      "    accuracy                           0.82       977\n",
      "   macro avg       0.82      0.82      0.82       977\n",
      "weighted avg       0.82      0.82      0.82       977\n",
      "\n",
      "Area Under Curve:    0.8167911260853532\n",
      "Precision:    0.8202479338842975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.6417974878028009\n",
      "Confusion Matrix : \n",
      " [[403  85]\n",
      " [ 90 399]]\n",
      "Accuracy on test set:    0.8208802456499488\n",
      "Sensitivity:    0.8159509202453987 \t Specificity:    0.8258196721311475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       488\n",
      "           1       0.82      0.82      0.82       489\n",
      "\n",
      "    accuracy                           0.82       977\n",
      "   macro avg       0.82      0.82      0.82       977\n",
      "weighted avg       0.82      0.82      0.82       977\n",
      "\n",
      "Area Under Curve:    0.8208852961882731\n",
      "Precision:    0.8243801652892562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.6110775860388001\n",
      "Confusion Matrix : \n",
      " [[395  93]\n",
      " [ 97 392]]\n",
      "Accuracy on test set:    0.8055271238485159\n",
      "Sensitivity:    0.8016359918200409 \t Specificity:    0.8094262295081968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       488\n",
      "           1       0.81      0.80      0.80       489\n",
      "\n",
      "    accuracy                           0.81       977\n",
      "   macro avg       0.81      0.81      0.81       977\n",
      "weighted avg       0.81      0.81      0.81       977\n",
      "\n",
      "Area Under Curve:    0.8055311106641189\n",
      "Precision:    0.8082474226804124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.5987947668953434\n",
      "Confusion Matrix : \n",
      " [[392  96]\n",
      " [100 389]]\n",
      "Accuracy on test set:    0.7993858751279427\n",
      "Sensitivity:    0.7955010224948875 \t Specificity:    0.8032786885245902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80       488\n",
      "           1       0.80      0.80      0.80       489\n",
      "\n",
      "    accuracy                           0.80       977\n",
      "   macro avg       0.80      0.80      0.80       977\n",
      "weighted avg       0.80      0.80      0.80       977\n",
      "\n",
      "Area Under Curve:    0.7993898555097388\n",
      "Precision:    0.8020618556701031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.6746218480592671\n",
      "Confusion Matrix : \n",
      " [[404  84]\n",
      " [ 75 414]]\n",
      "Accuracy on test set:    0.8372569089048106\n",
      "Sensitivity:    0.8466257668711656 \t Specificity:    0.8278688524590164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84       488\n",
      "           1       0.83      0.85      0.84       489\n",
      "\n",
      "    accuracy                           0.84       977\n",
      "   macro avg       0.84      0.84      0.84       977\n",
      "weighted avg       0.84      0.84      0.84       977\n",
      "\n",
      "Area Under Curve:    0.8372473096650911\n",
      "Precision:    0.8313253012048193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.6377261112458866\n",
      "Confusion Matrix : \n",
      " [[404  85]\n",
      " [ 92 396]]\n",
      "Accuracy on test set:    0.8188331627430911\n",
      "Sensitivity:    0.8114754098360656 \t Specificity:    0.8261758691206544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       489\n",
      "           1       0.82      0.81      0.82       488\n",
      "\n",
      "    accuracy                           0.82       977\n",
      "   macro avg       0.82      0.82      0.82       977\n",
      "weighted avg       0.82      0.82      0.82       977\n",
      "\n",
      "Area Under Curve:    0.8188256394783601\n",
      "Precision:    0.8232848232848233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.6868286849797665\n",
      "Confusion Matrix : \n",
      " [[415  74]\n",
      " [ 79 409]]\n",
      "Accuracy on test set:    0.8433981576253838\n",
      "Sensitivity:    0.8381147540983607 \t Specificity:    0.8486707566462167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       489\n",
      "           1       0.85      0.84      0.84       488\n",
      "\n",
      "    accuracy                           0.84       977\n",
      "   macro avg       0.84      0.84      0.84       977\n",
      "weighted avg       0.84      0.84      0.84       977\n",
      "\n",
      "Area Under Curve:    0.8433927553722889\n",
      "Precision:    0.8467908902691511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.658523527523186\n",
      "Confusion Matrix : \n",
      " [[414  75]\n",
      " [ 92 396]]\n",
      "Accuracy on test set:    0.8290685772773797\n",
      "Sensitivity:    0.8114754098360656 \t Specificity:    0.8466257668711656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       489\n",
      "           1       0.84      0.81      0.83       488\n",
      "\n",
      "    accuracy                           0.83       977\n",
      "   macro avg       0.83      0.83      0.83       977\n",
      "weighted avg       0.83      0.83      0.83       977\n",
      "\n",
      "Area Under Curve:    0.8290505883536157\n",
      "Precision:    0.8407643312101911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.6317060625913142\n",
      "Confusion Matrix : \n",
      " [[405  84]\n",
      " [ 96 392]]\n",
      "Accuracy on test set:    0.8157625383828045\n",
      "Sensitivity:    0.8032786885245902 \t Specificity:    0.8282208588957055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       489\n",
      "           1       0.82      0.80      0.81       488\n",
      "\n",
      "    accuracy                           0.82       977\n",
      "   macro avg       0.82      0.82      0.82       977\n",
      "weighted avg       0.82      0.82      0.82       977\n",
      "\n",
      "Area Under Curve:    0.8157497737101479\n",
      "Precision:    0.8235294117647058\n",
      "Matthews Correlation :  0.6479082768012435\n",
      "Confusion Matrix : \n",
      " [[402  87]\n",
      " [ 85 403]]\n",
      "Accuracy on test set:    0.8239508700102354\n",
      "Sensitivity:    0.8258196721311475 \t Specificity:    0.8220858895705522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82       489\n",
      "           1       0.82      0.83      0.82       488\n",
      "\n",
      "    accuracy                           0.82       977\n",
      "   macro avg       0.82      0.82      0.82       977\n",
      "weighted avg       0.82      0.82      0.82       977\n",
      "\n",
      "Area Under Curve:    0.8239527808508498\n",
      "Precision:    0.8224489795918367\n",
      "Mean MCC = 0.6423 + 0.0253 and Mean AUC = 0.8211 + 0.0126\n",
      "Mean MCC:    0.6422593156376277\n",
      "Mean Sensitivity = 0.8162 + 0.0154 and Mean Specificity = 0.8260 + 0.0133 and Mean Accuracy = 0.8211 + 0.0126\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    seed = i\n",
    "    print(\"Seed : \",seed)\n",
    "    rus = RandomUnderSampler(random_state = seed)\n",
    "    X_train, y_train = rus.fit_resample(X_train_full,y_train_full)\n",
    "\n",
    "    X_train, y_train = shuffle(X_train,y_train)\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    MCC = []\n",
    "    kfold = StratifiedKFold(n_splits=10)\n",
    "    cvscores, auc_scores, sn, sp, acc = list(), list(), list(), list(), list()\n",
    "\n",
    "    for train_index, test_index in kfold.split(X_train, y_train):\n",
    "        xtrain, xval = X_train[train_index], X_train[test_index]\n",
    "        ytrain, yval = y_train[train_index], y_train[test_index]      \n",
    "\n",
    "        X_train_10= xtrain\n",
    "        Y_train_10=ytrain\n",
    "\n",
    "        from sklearn.metrics import roc_curve, roc_auc_score, classification_report, auc\n",
    "        from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "        rus = RandomUnderSampler(random_state = seed)\n",
    "\n",
    "        clf = LogisticRegression(penalty='l2',solver='lbfgs',random_state=seed)\n",
    "\n",
    "        clf.fit(X_train_10, Y_train_10)\n",
    "       \n",
    "        \n",
    "        y_pred = np.array(clf.predict(xval))\n",
    "   \n",
    "        confusion = confusion_matrix(yval,y_pred)\n",
    "\n",
    "        print(\"Matthews Correlation : \",matthews_corrcoef(yval,y_pred))\n",
    "        print(\"Confusion Matrix : \\n\",confusion_matrix(yval,y_pred))\n",
    "        print(\"Accuracy on test set:   \",accuracy_score(yval,y_pred))\n",
    "\n",
    "        cm = confusion_matrix(yval,y_pred)\n",
    "\n",
    "        TP = cm[1][1]\n",
    "        TN = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "\n",
    "        mcc = matthews_corrcoef(yval,y_pred)\n",
    "\n",
    "        Sensitivity = TP/(TP+FN)\n",
    "\n",
    "        Specificity = TN/(TN+FP)\n",
    "\n",
    "        print(\"Sensitivity:   \",Sensitivity,\"\\t\",\"Specificity:   \",Specificity)\n",
    "\n",
    "        print(classification_report(yval,y_pred))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(yval,y_pred)\n",
    "\n",
    "        roc_auc_test = auc(fpr,tpr)\n",
    "\n",
    "\n",
    "\n",
    "        print(\"Area Under Curve:   \",roc_auc_test)\n",
    "\n",
    "        print(\"Precision:   \",TP/(TP+FP))\n",
    "        \n",
    "        acc.append(accuracy_score(yval, y_pred))\n",
    "        \n",
    "        cvscores.append(mcc)\n",
    "        \n",
    "        sn.append(Sensitivity)\n",
    "        sp.append(Specificity)\n",
    "\n",
    "        auc_scores.append(roc_auc_test) \n",
    "\n",
    "\n",
    "    print(\"Mean MCC = %.4f + %.4f and Mean AUC = %.4f + %.4f\" % (np.mean(cvscores),np.std(cvscores),np.mean(auc_scores),np.std(auc_scores)))\n",
    "    MCC.append(np.mean(cvscores))\n",
    "\n",
    "    print(\"Mean MCC:   \",np.mean(MCC))\n",
    "    print(\"Mean Sensitivity = %.4f + %.4f and Mean Specificity = %.4f + %.4f and Mean Accuracy = %.4f + %.4f\" % (np.mean(sn),np.std(sn),np.mean(sp),np.std(sp),np.mean(acc),np.std(acc)))\n",
    "\n",
    "    print(\"\\n\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c4be57",
   "metadata": {},
   "source": [
    "# Independent Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8412b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/t326h379/OGP\")\n",
    "\n",
    "\n",
    "df_negative = pd.read_csv('Feature_Extraction_O_linked_Training_Negative_114307_Sites_less.txt',header=None)\n",
    "\n",
    "df_positive = pd.read_csv('Feature_Extraction_O_linked_Training_Positive_4885_Sites_less.txt',header=None)\n",
    "\n",
    "Header_name = [\"Position\",\"PID\",\"Position_redundant\",\"81 Window sequence\",\"S or T\"]\n",
    "\n",
    "col_of_feature = [i for i in range(1,1025)]\n",
    "\n",
    "Header_name = Header_name + col_of_feature\n",
    "\n",
    "df_positive.columns = Header_name\n",
    "df_negative.columns = Header_name\n",
    "\n",
    "\n",
    "frames = [df_positive, df_negative]\n",
    "\n",
    "O_linked_training = pd.concat(frames,ignore_index = True)\n",
    "\n",
    "df_Train_array = O_linked_training.drop([\"Position\",\"PID\",\"Position_redundant\",\"81 Window sequence\",\"S or T\"],axis=1)\n",
    "df_Train_array = np.array(df_Train_array)\n",
    "\n",
    "X_train_full = df_Train_array\n",
    "\n",
    "y_train_full = np.array([1]*4885+[0]*114144)\n",
    "\n",
    "a = random.sample(range(1, 1000000), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76292621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent Test Dataset\n",
    "df_negative_test = pd.read_csv('Feature_Extraction_O_linked_Testing_Negative_11466_Sites_less.txt',header=None)\n",
    "\n",
    "df_positive_test = pd.read_csv('Feature_Extraction_O_linked_Testing_Positive_375_Sites_less.txt',header=None)\n",
    "\n",
    "Header_name = [\"Position\",\"PID\",\"Position_redundant\",\"81 Window sequence\",\"S or T\"]\n",
    "\n",
    "col_of_feature = [i for i in range(1,1025)]\n",
    "\n",
    "Header_name = Header_name + col_of_feature\n",
    "\n",
    "df_positive_test.columns = Header_name\n",
    "\n",
    "df_negative_test.columns = Header_name\n",
    "\n",
    "\n",
    "frames_test = [df_positive_test, df_negative_test]\n",
    "\n",
    "O_linked_testing = pd.concat(frames_test,ignore_index = True)\n",
    "\n",
    "df_Test_array = O_linked_testing.drop([\"Position\",\"PID\",\"Position_redundant\",\"81 Window sequence\",\"S or T\"],axis=1)\n",
    "df_Test_array = np.array(df_Test_array)\n",
    "\n",
    "X_test_full = df_Test_array\n",
    "\n",
    "y_test_full = np.array([1]*374+[0]*11466)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "235ba096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119029, 1024) (119029,) (11840, 1024) (11840,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.shape,y_train_full.shape,X_test_full.shape,y_test_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84cc8b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed :  437456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.5329641044922544\n",
      "Confusion Matrix : \n",
      " [[314  60]\n",
      " [117 257]]\n",
      "Accuracy on test set:    0.7633689839572193\n",
      "Sensitivity:    0.6871657754010695 \t Specificity:    0.839572192513369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78       374\n",
      "           1       0.81      0.69      0.74       374\n",
      "\n",
      "    accuracy                           0.76       748\n",
      "   macro avg       0.77      0.76      0.76       748\n",
      "weighted avg       0.77      0.76      0.76       748\n",
      "\n",
      "Area Under Curve:    0.7633689839572192\n",
      "Precision:    0.8107255520504731\n",
      "Seed :  664482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.542912203416473\n",
      "Confusion Matrix : \n",
      " [[314  60]\n",
      " [113 261]]\n",
      "Accuracy on test set:    0.7687165775401069\n",
      "Sensitivity:    0.6978609625668449 \t Specificity:    0.839572192513369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.78       374\n",
      "           1       0.81      0.70      0.75       374\n",
      "\n",
      "    accuracy                           0.77       748\n",
      "   macro avg       0.77      0.77      0.77       748\n",
      "weighted avg       0.77      0.77      0.77       748\n",
      "\n",
      "Area Under Curve:    0.7687165775401069\n",
      "Precision:    0.8130841121495327\n",
      "Seed :  111916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.5093858537542719\n",
      "Confusion Matrix : \n",
      " [[305  69]\n",
      " [116 258]]\n",
      "Accuracy on test set:    0.7526737967914439\n",
      "Sensitivity:    0.6898395721925134 \t Specificity:    0.8155080213903744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77       374\n",
      "           1       0.79      0.69      0.74       374\n",
      "\n",
      "    accuracy                           0.75       748\n",
      "   macro avg       0.76      0.75      0.75       748\n",
      "weighted avg       0.76      0.75      0.75       748\n",
      "\n",
      "Area Under Curve:    0.752673796791444\n",
      "Precision:    0.7889908256880734\n",
      "Seed :  219936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.546071955077617\n",
      "Confusion Matrix : \n",
      " [[309  65]\n",
      " [106 268]]\n",
      "Accuracy on test set:    0.7713903743315508\n",
      "Sensitivity:    0.7165775401069518 \t Specificity:    0.8262032085561497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78       374\n",
      "           1       0.80      0.72      0.76       374\n",
      "\n",
      "    accuracy                           0.77       748\n",
      "   macro avg       0.77      0.77      0.77       748\n",
      "weighted avg       0.77      0.77      0.77       748\n",
      "\n",
      "Area Under Curve:    0.7713903743315508\n",
      "Precision:    0.8048048048048048\n",
      "Seed :  568000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.5487468626834576\n",
      "Confusion Matrix : \n",
      " [[316  58]\n",
      " [113 261]]\n",
      "Accuracy on test set:    0.7713903743315508\n",
      "Sensitivity:    0.6978609625668449 \t Specificity:    0.8449197860962567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79       374\n",
      "           1       0.82      0.70      0.75       374\n",
      "\n",
      "    accuracy                           0.77       748\n",
      "   macro avg       0.78      0.77      0.77       748\n",
      "weighted avg       0.78      0.77      0.77       748\n",
      "\n",
      "Area Under Curve:    0.7713903743315508\n",
      "Precision:    0.8181818181818182\n",
      "Seed :  318959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.4855479423139216\n",
      "Confusion Matrix : \n",
      " [[308  66]\n",
      " [129 245]]\n",
      "Accuracy on test set:    0.7393048128342246\n",
      "Sensitivity:    0.6550802139037433 \t Specificity:    0.8235294117647058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76       374\n",
      "           1       0.79      0.66      0.72       374\n",
      "\n",
      "    accuracy                           0.74       748\n",
      "   macro avg       0.75      0.74      0.74       748\n",
      "weighted avg       0.75      0.74      0.74       748\n",
      "\n",
      "Area Under Curve:    0.7393048128342246\n",
      "Precision:    0.7877813504823151\n",
      "Seed :  870487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.544239178478916\n",
      "Confusion Matrix : \n",
      " [[311  63]\n",
      " [109 265]]\n",
      "Accuracy on test set:    0.7700534759358288\n",
      "Sensitivity:    0.7085561497326203 \t Specificity:    0.8315508021390374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78       374\n",
      "           1       0.81      0.71      0.75       374\n",
      "\n",
      "    accuracy                           0.77       748\n",
      "   macro avg       0.77      0.77      0.77       748\n",
      "weighted avg       0.77      0.77      0.77       748\n",
      "\n",
      "Area Under Curve:    0.7700534759358288\n",
      "Precision:    0.8079268292682927\n",
      "Seed :  62644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.546404180620424\n",
      "Confusion Matrix : \n",
      " [[310  64]\n",
      " [107 267]]\n",
      "Accuracy on test set:    0.7713903743315508\n",
      "Sensitivity:    0.713903743315508 \t Specificity:    0.8288770053475936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78       374\n",
      "           1       0.81      0.71      0.76       374\n",
      "\n",
      "    accuracy                           0.77       748\n",
      "   macro avg       0.78      0.77      0.77       748\n",
      "weighted avg       0.78      0.77      0.77       748\n",
      "\n",
      "Area Under Curve:    0.7713903743315508\n",
      "Precision:    0.8066465256797583\n",
      "Seed :  393435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation :  0.5475000633157839\n",
      "Confusion Matrix : \n",
      " [[313  61]\n",
      " [110 264]]\n",
      "Accuracy on test set:    0.7713903743315508\n",
      "Sensitivity:    0.7058823529411765 \t Specificity:    0.8368983957219251\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79       374\n",
      "           1       0.81      0.71      0.76       374\n",
      "\n",
      "    accuracy                           0.77       748\n",
      "   macro avg       0.78      0.77      0.77       748\n",
      "weighted avg       0.78      0.77      0.77       748\n",
      "\n",
      "Area Under Curve:    0.7713903743315509\n",
      "Precision:    0.8123076923076923\n",
      "Seed :  747864\n",
      "Matthews Correlation :  0.4900340716007037\n",
      "Confusion Matrix : \n",
      " [[300  74]\n",
      " [118 256]]\n",
      "Accuracy on test set:    0.7433155080213903\n",
      "Sensitivity:    0.6844919786096256 \t Specificity:    0.8021390374331551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76       374\n",
      "           1       0.78      0.68      0.73       374\n",
      "\n",
      "    accuracy                           0.74       748\n",
      "   macro avg       0.75      0.74      0.74       748\n",
      "weighted avg       0.75      0.74      0.74       748\n",
      "\n",
      "Area Under Curve:    0.7433155080213903\n",
      "Precision:    0.7757575757575758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t326h379/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    seed = i\n",
    "    print(\"Seed : \",seed)\n",
    "    rus = RandomUnderSampler(random_state = seed)\n",
    "    X_train, y_train = rus.fit_resample(X_train_full,y_train_full)\n",
    "\n",
    "    X_train, y_train = shuffle(X_train,y_train)\n",
    "\n",
    "    rus = RandomUnderSampler(random_state = seed)\n",
    "\n",
    "    clf = LogisticRegression(penalty='l2',solver='lbfgs',random_state=seed)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_test_random_undersample, y_test_random_undersample = rus.fit_resample(X_test_full,y_test_full)\n",
    "\n",
    "\n",
    "    y_pred = np.array(clf.predict(X_test_random_undersample))\n",
    "\n",
    "    confusion = confusion_matrix(y_test_random_undersample,y_pred)\n",
    "\n",
    "    print(\"Matthews Correlation : \",matthews_corrcoef(y_test_random_undersample,y_pred))\n",
    "    print(\"Confusion Matrix : \\n\",confusion_matrix(y_test_random_undersample,y_pred))\n",
    "    print(\"Accuracy on test set:   \",accuracy_score(y_test_random_undersample,y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test_random_undersample,y_pred)\n",
    "\n",
    "    TP = cm[1][1]\n",
    "    TN = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "\n",
    "    mcc = matthews_corrcoef(y_test_random_undersample,y_pred)\n",
    "\n",
    "    Sensitivity = TP/(TP+FN)\n",
    "\n",
    "    Specificity = TN/(TN+FP)\n",
    "\n",
    "    print(\"Sensitivity:   \",Sensitivity,\"\\t\",\"Specificity:   \",Specificity)\n",
    "\n",
    "    print(classification_report(y_test_random_undersample,y_pred))\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test_random_undersample,y_pred)\n",
    "\n",
    "    roc_auc_test = auc(fpr,tpr)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Area Under Curve:   \",roc_auc_test)\n",
    "\n",
    "    print(\"Precision:   \",TP/(TP+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b001fa1f",
   "metadata": {},
   "source": [
    "# Thank You!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f3131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4-TensorFlow-2.3.1-cuda [jupyter_python]",
   "language": "python",
   "name": "sys_python_3.7.4-tensorflow-2.3.1-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
