{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hll 1 Wrld 2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "String123 = 'Hello 1 World 2'\n",
    "\n",
    "print(re.sub(r'[aeiouAEIOU]','',String123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a-b-c\n"
     ]
    }
   ],
   "source": [
    "L = ['a','b','c']\n",
    "print('-'.join(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlrow olleh\n"
     ]
    }
   ],
   "source": [
    "q3 = 'hello world'\n",
    "print(q3[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def is_anagram(s1,s2):\n",
    "    #Sort characters of list in ascending order and compare, if equal then return True\n",
    "    return sorted(s1) == sorted(s2)\n",
    "\n",
    "print(is_anagram('listen','silenti'))\n",
    "print(is_anagram('listen','silent'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'assignment', '1', 'for', 'my', 'NLP', 'class']\n",
      "['this is ', 'ssignment 1 for my NLP cl', 'ss']\n",
      "['th', 's ', 's ass', 'gnment 1 for my NLP class']\n"
     ]
    }
   ],
   "source": [
    "string = 'this is assignment 1 for my NLP class'\n",
    "print(string.split())\n",
    "print(string.split('a'))\n",
    "print(string.split('i'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi how are you                      '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystring = '                     hi how are you                      '\n",
    "mystring.lstrip()\n",
    "#Removes spaces from left side of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                     hi how are you'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystring.rstrip()\n",
    "#Removes spaces from right side of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi how are you'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystring.strip()\n",
    "#Removes spaces from both sides of string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello How Are You'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystring = 'hello how are you'\n",
    "mystring.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-----------+-------------+\n",
      "| Datatype                  | Mutable   | Immutable   |\n",
      "+===========================+===========+=============+\n",
      "| List                      | Yes       | No          |\n",
      "+---------------------------+-----------+-------------+\n",
      "| Dictionary                | Yes       | No          |\n",
      "+---------------------------+-----------+-------------+\n",
      "| Set                       | Yes       | No          |\n",
      "+---------------------------+-----------+-------------+\n",
      "| User-defined classes      | Yes       | Yes         |\n",
      "+---------------------------+-----------+-------------+\n",
      "| Int, float, decimal, bool | No        | Yes         |\n",
      "+---------------------------+-----------+-------------+\n",
      "| String                    | No        | Yes         |\n",
      "+---------------------------+-----------+-------------+\n",
      "| Tuple                     | No        | Yes         |\n",
      "+---------------------------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "data = [\n",
    "    [\"List\", \"Yes\", \"No\"],\n",
    "    [\"Dictionary\", \"Yes\", \"No\"],\n",
    "    [\"Set\", \"Yes\", \"No\"],\n",
    "    [\"User-defined classes\", \"Yes\", \"Yes\"],\n",
    "    [\"Int, float, decimal, bool\", \"No\", \"Yes\"],\n",
    "    [\"String\", \"No\", \"Yes\"],\n",
    "    [\"Tuple\", \"No\", \"Yes\"]\n",
    "]\n",
    "print(tabulate(data, headers=[\"Datatype\", \"Mutable\", \"Immutable\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Are lists mutable in python?*\n",
    "Lists can be modified and values can be updated, therefore lists are mutable in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Are strings mutable in python?* Strings cannot be updated, as 'updating' a string actually only creates a new string object, not changing the original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Mukesh 25\n",
      "1 Roni 50\n",
      "2 Charti 18\n"
     ]
    }
   ],
   "source": [
    "names = ['Mukesh', 'Roni', 'Charti']\n",
    "ages = [25, 50, 18]\n",
    "\n",
    "for i, (name, age) in enumerate(zip(names, ages)):\n",
    "    print(i, name, age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mukesh', 25), ('Roni', 50), ('Charti', 18)]\n"
     ]
    }
   ],
   "source": [
    "k = list(zip(names, ages))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 2, 'cat': 4, 'guinea pig': 10, 'parrot': 2}\n"
     ]
    }
   ],
   "source": [
    "pets = ['dog','cat','guinea pig', 'parrot']\n",
    "numbers = [2,4,10,2]\n",
    "pet_numbers_dict = {}\n",
    "for animal,num in zip(pets,numbers):\n",
    "    pet_numbers_dict[animal] = num\n",
    "print(pet_numbers_dict)\n",
    "\n",
    "##The program uses zip and two lists to create a dictionary, associating each pet key with a number value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 13**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letters are: {'e', 's', 'g', 'k'}\n",
      "Letters are: {'e', 's', 'g', 'k'}\n"
     ]
    }
   ],
   "source": [
    "GEEK = {'g','e','k'}\n",
    "GEEK.add('s')\n",
    "print(\"Letters are:\", GEEK)\n",
    "\n",
    "GEEK.add('s')\n",
    "print(\"Letters are:\", GEEK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 14**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 is not a prime number.\n",
      "7 is a prime number.\n"
     ]
    }
   ],
   "source": [
    "def is_prime(num):\n",
    "    notPrime = False\n",
    "    if num <= 1:\n",
    "        print(str(num) + \" is not a prime number.\")\n",
    "    elif num == 2:\n",
    "        print(str(num) + \" is a prime number.\")\n",
    "    for i in range(2, int(num ** 0.5) + 1):\n",
    "        if num % i == 0:\n",
    "            notPrime = True\n",
    "            print(str(num) + \" is not a prime number.\")\n",
    "            break\n",
    "    if notPrime == False:\n",
    "        print(str(num) + \" is a prime number.\")  \n",
    "\n",
    "\n",
    "is_prime(8)\n",
    "is_prime(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 15**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 1 2 3 5 8 13 21 34 "
     ]
    }
   ],
   "source": [
    "def fib_series(n):\n",
    "    a, b = 0, 1\n",
    "    for i in range(n):\n",
    "        print(a, end=\" \")\n",
    "        a, b = b, a + b\n",
    "\n",
    "n = 10\n",
    "fib_series(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = 27\n",
      "R = 13\n",
      "N = 35\n",
      "D = 25\n",
      "C = 11\n",
      "E = 42\n",
      "Q = 23\n",
      "G = 19\n",
      "H = 9\n",
      "I = 43\n",
      "L = 43\n",
      "K = 44\n",
      "M = 6\n",
      "F = 26\n",
      "P = 26\n",
      "S = 51\n",
      "T = 36\n",
      "W = 13\n",
      "Y = 22\n",
      "V = 43\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "url = \"https://rest.uniprot.org/uniprotkb/P17181.fasta\"\n",
    "response = request.urlopen(url)\n",
    "fasta = response.read().decode('utf8')\n",
    "\n",
    "sequence = ''.join(fasta.splitlines()[1:])\n",
    "\n",
    "amino_acids = 'ARNDCEQGHILKMFPSTWYV'\n",
    "freq_dist = FreqDist(sequence)\n",
    "\n",
    "amino_counts = {}\n",
    "for indiv_amino in amino_acids:\n",
    "    amino_counts[indiv_amino] = freq_dist[indiv_amino]\n",
    "\n",
    "for indiv_amino, count in amino_counts.items():\n",
    "    print(f\"{indiv_amino} = {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 17**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding is a technique for converting categorical variables to a numerical format, where you have a matrix(dataset) of categorical variables, and rows indicating one(it is the label) and zero(it is not the label). So for labels such as red, gren and yellow, a one hot encoded red value would be [1,0,0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding is used to encode the amino acid sequences by assigning encoded values to the amino sequences. If A encoded is [1,0,0,...,0], P is encoded [0,0,1,...,0], and D is encoded [0,1,0,...,0] then a sequence of APD is encoded as [[1,0,0,...,0],[0,0,1,...,0],[0,1,0,...,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's advantages are that it is effective for many ML models and maintains disctinction between different categorical variables while its disadvantages inlcude its high dimensionality(large vectors/matrices for many variables) and high memory usage(for large datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I were a data scientist, I would probably use one hot encoding in some of my projects depending on the use case. If I have a large amount of labels to be encoded, it would most likely be better for me to use a different form of encoding, as it might be hard to understand the encoded data and would take up much more memory than other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create a dictionary that maps each amino acid to an integer\n",
    "aminoList = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "aminoDict = {amino: i for i, amino in enumerate(aminoList)}\n",
    "aminoDict\n",
    "\n",
    "#Function that one-hot encodes a sequence\n",
    "def one_hot_encode(sequence, aminoDict = aminoDict):\n",
    "    #Create a matrix of zeros\n",
    "    one_hot = np.zeros((len(sequence), len(aminoDict)))\n",
    "    #Set the appropriate elements to 1\n",
    "    for i, amino in enumerate(sequence):\n",
    "        one_hot[i, aminoDict[amino]] = 1\n",
    "\n",
    "    #Return the one-hot encoded sequence\n",
    "    return one_hot\n",
    "\n",
    "sequence = 'ACDGKINWE'\n",
    "one_hot = one_hot_encode(sequence)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 18**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert words to integer values before passing to a model because neural networks and machine learning models operate on and process numerical data, not text data. This also reduces the complexity of models. Since computers dont inherently 'understand' words, we must convert the data to integer values in order to use models and algorithms to reach our end goal of what we wish to do with the data. Tokenizing the text and then converting those tokens into integer IDs allows us to process textual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 19**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code starts off with assigning a numpy array of feature vectors, each one associated (told to us through code comments) witha specific word. \"Your\" is assigned the feature vector of [0.43, 0.15, 0.89], for example. The code shows the shape of the array, which shows us that it has 6 words and 3 features identifying the words. The print(inputs.shape[0]) line just shows us how many words we have, which is 6. The query = inputs[1] assigns us a variable of \"query\" to [0.55, 0.87, 0.66] (which is the \"journey\" word's feature vector). The code then creates an attention scores array of size 6 (the number of words we have in our vocabulary). The code then iterates over each feature vector in the inputs array and calculates an attention score (dot product of the the iterated and the query feature vectors) for each of the feature vectors. The attention score represents the similarity between each word's feature vector in the vocabulary and the query word(the higher the attention score, the more similar it is to the query word's feature vector)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 20**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is similar to the code from question 20, however *while the code above only calculates the attention scores of each word compared to a query, this code computes the attention scores of each word compared to a query and then normalizes it into an attention weight by dividing each attention scores by the sum of all the attention scores.* Normalization is important because it allows the attention weights to contribute more to the final output if the weight is higher. This program also displays that the sum of all attention weights is 1(which makes sense since the weights are meant to function like a weighted average or a weighted percentage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 21**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is also similar to question 19's code, however while the code from question 19 only calculates the attention score for a query word and the words in the inputs array, *this code calculates the attention scores of each possible word pair in the inputs vocabulary, making it more useful for an attention score driven model.* Attention score is, as I mentioned before, calculated by performing the dot product of two words' feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the second code snippet, the code uses *inputs @ inputs.T* to calculate the attention score matrix, which is better than dot product because the time complexity of a nested for loop is O(n^2). The @ operator is a matrix multiplication operator and is inherently faster than using a manual for loop for the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 22**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first code snippet has an output of [4.46   6.5617 6.4801 3.6459 3.1863 4.673 ], which is the sum of each column printed as a vector. The code is taking a 6x6 matrix and calculating the sum of each column, and saving it to a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second code snippet is creating a 6x6 matrix of random values between 0 and 1, with 2 decimal places, and summing each row and storing it in a vector. The outputs are the random matrix, and the vector of each row's sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 23**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet shows a usage of the np.tril function, which takes a matrix and sets all values above and to the right of the diagonal to 0(it keeps the values along the diagonal). We also see the code set all values that were set to 0 by the tril function to -inf. This technique can and is used in NLP during model training, so that the model does not look ahead in the tokens when training the model, as we need it to be predicting a future token using tokens it has, not using tokens it already knows is there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 24**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code provided creates a 3D array of 3 batches of logits(raw output of a NN model). Often, the NN's final output is the last token's logits. The *last_token_logits = logits[:, -1, :]* line extracts the last logit vector in each batch, and adds it to an array named \"last_token_logits\". This is being done to extract (presumably a NN's output) from the rest of the logits, essentially extracting the model's final output tokens. The program then prints the original shape, the last token logits shape, and prints the values in the last token logits array."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
