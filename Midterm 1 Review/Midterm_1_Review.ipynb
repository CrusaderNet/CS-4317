{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M': 6, 'K': 8, 'R': 4, 'T': 13, 'P': 13, 'Q': 2, 'Y': 2, 'S': 9, 'N': 2, 'G': 7, 'C': 6, 'F': 5, 'A': 5, 'W': 7, 'H': 5, 'V': 10, 'E': 3, 'D': 2, 'I': 1, 'L': 3}\n"
     ]
    }
   ],
   "source": [
    "#Please write a program to count the number of amino acids in the protein file.\n",
    "def aminoCount(seq):\n",
    "    count = {}\n",
    "\n",
    "    for char in seq:\n",
    "        count[char] = seq.count(char)\n",
    "    \n",
    "    return count\n",
    "\n",
    "seq = \"\"\n",
    "\n",
    "with open(\"G3V5D1.txt\") as file:\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        for char in line:\n",
    "            if char == '\\n':\n",
    "                continue\n",
    "            else:\n",
    "                seq += char\n",
    "            \n",
    "print(aminoCount(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How do you find the spelling errors in the list using the word list corpus.*\n",
    "\n",
    "You find spelling errors in the list using the word list corpus by searching the words corpus for the input words, and if they are not in the word list corpus, then the words are misspelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word is spelled correctly.\n"
     ]
    }
   ],
   "source": [
    "#How do you find the spelling errors in the list using the word list corpus. Write a program for it.\n",
    "\n",
    "from nltk.corpus import words\n",
    "\n",
    "word_list = words.words()\n",
    "\n",
    "word = \"guardian\"\n",
    "\n",
    "if word in word_list:\n",
    "    print(\"The word is spelled correctly.\")\n",
    "else:\n",
    "    print(\"The word is spelled incorrectly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What is the difference between lemmatization and stemming, provide some examples for it.*\n",
    "\n",
    "Lemmatization is the process of taking a word and reducing it to it's base form while checking that it is still a word in a known dictionary. Stemming is the process of reducing a word to a based form by removing its affixes. \n",
    "\n",
    "An example of this would be the word \"Caring\". While Lemmatization would correctly reduce the word to the base form \"Care\", Stemming would instead only remove the suffix '-ing' and reduce the word to an incorrect base form of \"Car\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional Frequency Distribution is a way to organize and analyze the frequency of occurences of a word in a text given a certain condition or a context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  can could   may might  must  will \n",
      "           news    93    86    66    38    50   389 \n",
      "       religion    82    59    78    12    54    71 \n",
      "        hobbies   268    58   131    22    83   264 \n",
      "science_fiction    16    49     4    12     8    16 \n",
      "        romance    74   193    11    51    45    43 \n",
      "          humor    16    30     8     8     9    13 \n"
     ]
    }
   ],
   "source": [
    "#What does the conditional frequency distribution plot show. Please explain it with a relevant program. \n",
    "import nltk.corpus\n",
    "from nltk.corpus import brown\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "                            (genre, word)\n",
    "                            for genre in brown.categories()\n",
    "                            for word in brown.words(categories=genre))\n",
    "\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "\n",
    "cfd.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['revolving']\n",
      "['enrol', 'ergon', 'genro', 'girl', 'girn', 'giro', 'giver', 'glor', 'glore', 'glover', 'goer', 'goner', 'gore', 'gorlin', 'govern', 'grein', 'grin', 'groin', 'grove', 'grovel', 'ignore', 'inro', 'involver', 'iron', 'irone', 'levir', 'lienor', 'lier', 'liner', 'linger', 'lire', 'liver', 'livor', 'livre', 'loir', 'longer', 'lore', 'lori', 'lorn', 'lover', 'lovering', 'negro', 'nigre', 'noiler', 'noir', 'nori', 'norie', 'ogler', 'ogre', 'oiler', 'oner', 'oriel', 'orle', 'over', 'overling', 'regin', 'region', 'reign', 'rein', 'renvoi', 'reoil', 'revolving', 'rigol', 'rile', 'rine', 'ring', 'ringe', 'ringle', 'rive', 'rivel', 'riven', 'roil', 'role', 'rone', 'rove', 'roving', 'vergi', 'veri', 'vier', 'vigor', 'viner', 'violer', 'vire', 'vireo', 'virl', 'virole', 'viron', 'viver', 'girl', 'iron', 'over', 'ring']\n"
     ]
    }
   ],
   "source": [
    "#Write a program for the following questions with the following scenario.\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import words\n",
    "\n",
    "def reqCheck(checkWord):\n",
    "    freq_req = {'e':1, 'g':1, 'i':1, 'v':2, 'r':1, 'o':1, 'n':1, 'l':1}\n",
    "    freq_word = FreqDist(checkWord)\n",
    "\n",
    "    if len(checkWord) >= 4:\n",
    "        if 'r' in checkWord:\n",
    "            if not checkWord.endswith('s'):\n",
    "                if not checkWord[0].isupper():\n",
    "                    if checkWord.isascii():\n",
    "                        for char in checkWord:\n",
    "                            if char not in freq_req:\n",
    "                                return False\n",
    "                        for char, freq in freq_word.items():\n",
    "                            if char in freq_req and freq > freq_req[char]:\n",
    "                                return False\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "wordList = words.words()\n",
    "\n",
    "valid_words = [word for word in wordList if reqCheck(word)]\n",
    "\n",
    "nine_letter_word = [word for word in valid_words if len(word) == 9]\n",
    "\n",
    "if nine_letter_word:\n",
    "    print(nine_letter_word)\n",
    "    print(valid_words)\n",
    "else:\n",
    "    print(\"No Nine Letter Words Found, Search Failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(30, 40), match='Mr Simpson'>\n",
      "<re.Match object; span=(53, 62), match='Mr. Brown'>\n",
      "<re.Match object; span=(72, 77), match='Mr. T'>\n"
     ]
    }
   ],
   "source": [
    "#Write a program to extract. Mr. Simpson, Mr. Brown and Mr. T from the following string. \n",
    "\n",
    "import re\n",
    "\n",
    "my_string = \"\"\"\n",
    "hello world\n",
    "1223 \n",
    "2020-05-20\n",
    "Mr Simpson\n",
    "Mrs Simpson\n",
    "Mr. Brown\n",
    "Ms Smith\n",
    "Mr. T\n",
    "\"\"\"\n",
    "pattern = re.compile(r\"Mr\\.?\\s\\w+\")\n",
    "\n",
    "matches = pattern.finditer(my_string)\n",
    "\n",
    "for match in matches:\n",
    "    print(match)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What is the objective of Natural Language Processing. Can you explain natural language processing \n",
    "pipeline.*\n",
    "\n",
    "The objective of Natural Language Processing is to enable computers to interpret, manipulate, and comprehend human lanugage in a meaningful way. We use Natural Laguage Processing to take, process and analyze natural language.\n",
    "\n",
    "The Natural Language Processing Pipeline is a series of stages that allow raw data to be transformed into a format that can be used for NLP tasks.\n",
    "\n",
    "From the NLP Pipeline Diagram(Provided in Lecture)\n",
    "- HTML: Download the web page\n",
    "- ASCII: Strip the HTML data to raw ASCII data\n",
    "- Text: Tokenize the ASCII text, select the tokens of interest, and create an NLTK text\n",
    "- Vocab: Normalize the words in the NLTK Text and build the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain concatenation, flatten, and argmax functions in the context of NumPy array? Why do you need a NumPy array?*\n",
    "\n",
    "- Concatenation: The concatenate() function joins two or more NumPy arrays along a specific axis. This helps combine arrays into one array.\n",
    "- Flatten: The flatten() function converts a multi-dimensional array into a single dimension array. It returns a copy of the original array in one dimension, while the ravel() array returns a view of the original array as a one dimensional array whenever possible.\n",
    "- ArgMax: The argmax() function is used to search and return the indices of the maximum values(first occurence) of a NumPy array along a specified axis. If no axis is specified, it flattens the array and returns the index of the largest value in the flattened array.\n",
    "\n",
    "NumPy arrays are needed because they come with a useful library of functions that are not available in the default arrays. NumPy arrays offer support for multidimensional data, and are designed to be efficient with numerical computations, and are more memory efficient than default python arrays(lists)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "#Write a program to display a unique element in the list, do not use set data structure?\n",
    "\n",
    "def freq_dict(inputs):\n",
    "    count_dict = {}\n",
    "\n",
    "    for element in inputs:\n",
    "        if element in count_dict:\n",
    "            continue\n",
    "        else:\n",
    "            count_dict[element] = 1\n",
    "\n",
    "    uniques = [element for element, count in count_dict.items() if count == 1]\n",
    "\n",
    "    return uniques\n",
    "\n",
    "data = [1, 1, 2, 3, 3, 4, 5, 6, 6, 6, 7, 7, 8, 9, 9, 9, 9, 10]\n",
    "\n",
    "unique_elements = freq_dict(data)\n",
    "\n",
    "print(unique_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first DataFrame'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>market_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banana</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avocado</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fruit  market_price\n",
       "0    apple            21\n",
       "1   banana            14\n",
       "2  avocado            35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The second DataFrame'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>wholesaler_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>banana</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avocado</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fruit  wholesaler_price\n",
       "0   banana                65\n",
       "1    apple                68\n",
       "2  avocado                75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>market_price</th>\n",
       "      <th>wholesaler_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>21</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banana</td>\n",
       "      <td>14</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avocado</td>\n",
       "      <td>35</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fruit  market_price  wholesaler_price\n",
       "0    apple            21                68\n",
       "1   banana            14                65\n",
       "2  avocado            35                75"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a program to merge two data frames based on a unique column? \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({\"fruit\" : [\"apple\", \"banana\", \"avocado\"],\n",
    "                    \"market_price\" : [21, 14, 35]})\n",
    "display(\"The first DataFrame\")\n",
    "display(df1)\n",
    "  \n",
    "# creating the second DataFrame\n",
    "df2 = pd.DataFrame({\"fruit\" : [\"banana\", \"apple\", \"avocado\"],\n",
    "                    \"wholesaler_price\" : [65, 68, 75]})\n",
    "display(\"The second DataFrame\")\n",
    "display(df2)\n",
    "\n",
    "pd.merge(df1, df2, on='fruit', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What is One Hot vector and Document Term matrix?*\n",
    "\n",
    "- One Hot vector: A One Hot Vector is a 1 x N vector(Matrix) to represent categorical data as binary vectors. Each element of categorical data is represented by a single 1 and multiple 0s in order to identify it from other elements. For example, if you have three elements of \"dog\", \"cat\", and \"mouse\", \"dog\" One Hot Encoded would be [1, 0, 0], \"cat\" would be encoded [0, 1, 0] and \"mouse\" would be encoded [0, 0, 1].\n",
    "\n",
    "- Document Term matrix: a document term matrix is a matrix in which each row represents a document, and each column represents a word in the documents. The value at the intersection of each row/column represents the frequency of that word in that document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What is TF-IDF, construct a TFID feature vector for the following four documents.*\n",
    "\n",
    "- TF-IDF: Term Frequency-Inverse Document Frequency. TF-IDF assigns a weight to each word in a document based on the importance of that word in the document. It is calculated by multiplying the term frequency (times a word appears in a document/number of words in the document) by the inverse document frequency(log(number of documents in the corpus/number of documents in the corpus that contain the word)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42389674 0.         0.64043405 0.64043405 0.        ]\n",
      " [0.7979221  0.         0.         0.60276058 0.        ]\n",
      " [0.42389674 0.         0.64043405 0.         0.64043405]\n",
      " [0.37919167 0.72664149 0.         0.         0.5728925 ]]\n"
     ]
    }
   ],
   "source": [
    "#Construct a TFIDF feature vector for the following four documents.\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.DataFrame({'text':['people watch campusx','campusx watch campusx','people write campusx','campusx write comment'],'output':[1,1,0,0]})\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X = tfidf.fit_transform(df['text']).toarray()\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 13**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain \n",
    "a. Lexical diversity \n",
    "b. Hypernyms, hyponyms \n",
    "c. Polysemy \n",
    "d. “Today is the midterm test 1” tokenize the string based upon the space. \n",
    "e. What is one hot vector list out its advantages and disadvantages.\n",
    "\n",
    "- Lexical Diversity: The lexical diversity is the number of times each vocabulary item appears in a text on average. It is a metric given to analyze the diversity of a text. It is calculated as a ratio of the unique words to the total number of words in a text.\n",
    "- Hypernyms: Hypernyms are words that are a broader topic of a specific word. For example, a Hypernym of \"Dog\" may be \"Animal\"\n",
    "- Hyponyms: Hyponyms are more specific words of a broader topic or category. For example, a Hyponym of \"Animal\" may be \"Cat\"\n",
    "- Polysemy: Polysemy is the phenomenon where a word may have multiple meanings or senses.\n",
    "- “Today is the midterm test 1” tokenize the string based upon the space: Tokenized Text: [\"Today\", \"is\", \"the\", \"midterm\", \"test\", \"1\"]\n",
    "- One Hot Vector: \n",
    "    - 1 x N vector(Matrix) to represent categorical data as binary vectors. Each element of categorical data is represented by a single 1 and multiple 0s in order to identify it from other elements. For example, if you have three elements of \"dog\", \"cat\", and \"mouse\", \"dog\" One Hot Encoded would be [1, 0, 0], \"cat\" would be encoded [0, 1, 0] and \"mouse\" would be encoded [0, 0, 1].\n",
    "    - Advantages: \n",
    "        - Effective for many ML Models\n",
    "        - Maintains distinction between different categorical variables\n",
    "    - Disadvantages:\n",
    "        - High dimensionality for many variables\n",
    "        - High memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 14**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain inheritance in object-oriented programming (OOP) with super() function in it, can you write a program for it. What are getters and setters in the context of OOP?*\n",
    "\n",
    "- Inheritance in OOP: Inheritance is a concept in OOP where a parent class can have child classes, inheriting all of the attributes of the parent class and including its own attributes. The super() function is used to call methods from the parent class in the context of the child class.\n",
    "- Getters and Setters in OOP are part of a concept called Encapsulation, which is the concept of hiding the internal state of an object by using getters and setters to control object access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Staff():\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "    def introduce(self):\n",
    "        return f\"Hi, I'm {self.name} and I am {self.age} years old\"\n",
    "\n",
    "class Professor(Staff):\n",
    "    def __init__(self, name, age, course):\n",
    "        super().__init__(name, age)\n",
    "        self.course = course\n",
    "    def profCourse(self):\n",
    "        return f\"My Name is {self.name} and I teach {self.course}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 15**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Can you explain the dot product concept in the NLP and why is it used with NLP program?*\n",
    "\n",
    "- Dot Product of two vectors is the sum of the products of their corresponding components. In NLP, it can be used in the calculation of similarity.\n",
    "- Dot Product is used in NLP for many things, one of them being the calculation of Cosine Similarity. Cosine Similarity is the measure of similarity between two non-zero vectors. Cosine Similarity is calculated by the dot product of two vectors divided by the product of their magnitudes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
